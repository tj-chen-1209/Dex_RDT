#!/usr/bin/env python
"""
é¢„å¤„ç†LeRobotæ•°æ®é›†ï¼Œç”Ÿæˆç¼“å­˜æ–‡ä»¶

è¿™ä¸ªè„šæœ¬éœ€è¦åœ¨æœ‰lerobotæˆ–pandasåº“çš„ç¯å¢ƒä¸­è¿è¡Œã€‚
è¿è¡Œåä¼šåœ¨æ•°æ®é›†ç›®å½•ä¸‹åˆ›å»ºcacheæ–‡ä»¶å¤¹ï¼ŒåŒ…å«ï¼š
- episode_metadata.pt: episodeå…ƒæ•°æ®
- episode_XXXXXX.pt: æ¯ä¸ªepisodeçš„state/action/imagesæ•°æ®

Usage:
    python preprocess_lerobot_cache.py --dataset_path data/baai/data/lerobot_baai
"""

import os
import json
import argparse
import numpy as np
import torch
from PIL import Image
from pathlib import Path
from tqdm import tqdm

# Try different import methods
USE_LEROBOT_API = False
USE_NATIVE = False

try:
    from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
    USE_LEROBOT_API = True
    print("âœ… ä½¿ç”¨LeRobot API")
except ImportError:
    try:
        import pandas as pd
        import pyarrow.parquet as pq
        USE_NATIVE = True
        print("âœ… ä½¿ç”¨åŸç”ŸParquetè¯»å–")
    except ImportError:
        print("âŒ éœ€è¦å®‰è£…lerobotæˆ–pandas+pyarrowåº“")
        exit(1)


class LerobotCacheGenerator:
    """ç”ŸæˆLeRobotæ•°æ®é›†çš„ç¼“å­˜æ–‡ä»¶"""
    
    def __init__(self, dataset_path: str):
        self.dataset_path = Path(dataset_path)
        self.cache_dir = self.dataset_path / "cache"
        
        # Create cache directory
        self.cache_dir.mkdir(exist_ok=True)
        
        # Load info
        with open(self.dataset_path / "meta" / "info.json") as f:
            self.info = json.load(f)
        
        print(f"ğŸ“‚ æ•°æ®é›†: {dataset_path}")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_dir}")
        print(f"ğŸ“Š æ€»Episodes: {self.info['total_episodes']}")
        print(f"ğŸ“Š æ€»Frames: {self.info['total_frames']}")
        
        if USE_LEROBOT_API:
            self.dataset = LeRobotDataset(str(self.dataset_path))
            print(f"âœ… LeRobotæ•°æ®é›†åŠ è½½æˆåŠŸ")
        elif USE_NATIVE:
            self._load_native_data()
    
    def _load_native_data(self):
        """ä½¿ç”¨åŸç”Ÿæ–¹æ³•åŠ è½½parquetæ•°æ®"""
        print("ğŸ“– æ­£åœ¨åŠ è½½Parquetæ•°æ®...")
        
        import pandas as pd
        all_data = []
        data_dir = self.dataset_path / "data"
        
        for chunk_dir in sorted(data_dir.glob("chunk-*")):
            for parquet_file in sorted(chunk_dir.glob("file-*.parquet")):
                print(f"  è¯»å–: {parquet_file.relative_to(self.dataset_path)}")
                df = pd.read_parquet(parquet_file)
                all_data.append(df)
        
        self.all_data = pd.concat(all_data, ignore_index=True)
        print(f"âœ… åŠ è½½å®Œæˆ: {len(self.all_data)} å¸§")
    
    def _get_frame(self, index):
        """è·å–å•å¸§æ•°æ®"""
        if USE_LEROBOT_API:
            return self.dataset[index]
        else:
            # Convert pandas row to dict
            row = self.all_data.iloc[index]
            frame = {}
            for col in self.all_data.columns:
                val = row[col]
                if isinstance(val, np.ndarray):
                    frame[col] = torch.from_numpy(val) if len(val.shape) > 0 else torch.tensor(val)
                else:
                    frame[col] = torch.tensor([val])
            return frame
    
    def _get_dataset_length(self):
        """è·å–æ•°æ®é›†é•¿åº¦"""
        if USE_LEROBOT_API:
            return len(self.dataset)
        else:
            return len(self.all_data)
    
    def generate_cache(self, save_images=True, decode_images=False, compress_images=False):
        """
        ç”Ÿæˆç¼“å­˜æ–‡ä»¶
        
        Args:
            save_images: æ˜¯å¦ä¿å­˜å›¾åƒã€‚å¦‚æœä¸ºFalseï¼Œåªä¿å­˜å›¾åƒè·¯å¾„ä¿¡æ¯ï¼ˆéœ€è¦è§†é¢‘è§£ç ï¼‰
            decode_images: æ˜¯å¦é¢„è§£ç å›¾åƒä¸ºnumpyæ•°ç»„ï¼ˆå¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦ï¼Œä½†å ç”¨æ›´å¤šç£ç›˜ç©ºé—´ï¼‰
            compress_images: æ˜¯å¦å‹ç¼©å›¾åƒï¼ˆéœ€è¦decode_images=Trueï¼‰
        """
        print("\n" + "="*70)
        print("ğŸ”„ å¼€å§‹ç”Ÿæˆç¼“å­˜")
        print("="*70)
        
        if decode_images:
            print("âš¡ é¢„è§£ç å›¾åƒæ¨¡å¼ï¼šå°†JPEGè§£ç ä¸ºnumpyæ•°ç»„ï¼ˆæå‡è®­ç»ƒé€Ÿåº¦3-4å€ï¼‰")
            if compress_images:
                print("ğŸ“¦ å‹ç¼©æ¨¡å¼ï¼šä½¿ç”¨uint8å‹ç¼©å­˜å‚¨ï¼ˆèŠ‚çœ50%ç£ç›˜ç©ºé—´ï¼‰")
        
        # Step 1: Calculate episode information
        print("\nğŸ“ æ­¥éª¤1: è®¡ç®—episodeå…ƒæ•°æ®...")
        episode_data, episode_lens = self._calculate_episodes()
        
        # Save episode metadata
        metadata_path = self.cache_dir / "episode_metadata.pt"
        torch.save({
            'episode_data': episode_data,
            'episode_lens': episode_lens
        }, metadata_path)
        print(f"âœ… ä¿å­˜å…ƒæ•°æ®: {metadata_path.name}")
        
        # Step 2: Process each episode
        print(f"\nğŸ“¦ æ­¥éª¤2: å¤„ç†å¹¶ç¼“å­˜æ¯ä¸ªepisode...")
        total_size = 0
        for ep_info in tqdm(episode_data, desc="å¤„ç†episodes"):
            cache_file = self._cache_episode(
                ep_info, 
                save_images=save_images,
                decode_images=decode_images,
                compress_images=compress_images
            )
            if cache_file and cache_file.exists():
                total_size += cache_file.stat().st_size
        
        print("\n" + "="*70)
        print("âœ… ç¼“å­˜ç”Ÿæˆå®Œæˆï¼")
        print("="*70)
        print(f"ğŸ“‚ ç¼“å­˜ä½ç½®: {self.cache_dir}")
        print(f"ğŸ“Š Episodeæ•°é‡: {len(episode_data)}")
        print(f"ğŸ’¾ æ€»å¤§å°: {total_size / 1024**3:.2f} GB")
        if decode_images:
            print(f"âš¡ é¢„æœŸè®­ç»ƒé€Ÿåº¦æå‡: 3-4å€ (16 it/s â†’ 60-80 it/s)")
        print(f"ğŸ’¾ å¯ä»¥åœ¨rdtç¯å¢ƒä¸­ä½¿ç”¨ lerobot_Dex_dataset.py åŠ è½½æ•°æ®")
    
    def _calculate_episodes(self):
        """è®¡ç®—episodeä¿¡æ¯"""
        episode_data = []
        episode_lens = []
        
        current_episode = -1
        episode_start = 0
        dataset_length = self._get_dataset_length()
        
        print(f"  æ€»å¸§æ•°: {dataset_length}")
        
        for i in tqdm(range(dataset_length), desc="æ‰«æepisodes"):
            frame = self._get_frame(i)
            ep_idx = frame['episode_index'].item()
            
            if ep_idx != current_episode:
                if current_episode != -1:
                    episode_len = i - episode_start
                    episode_data.append({
                        'episode_idx': current_episode,
                        'start_idx': episode_start,
                        'end_idx': i,
                        'length': episode_len
                    })
                    episode_lens.append(episode_len)
                
                current_episode = ep_idx
                episode_start = i
        
        # Last episode
        if current_episode != -1:
            episode_len = dataset_length - episode_start
            episode_data.append({
                'episode_idx': current_episode,
                'start_idx': episode_start,
                'end_idx': dataset_length,
                'length': episode_len
            })
            episode_lens.append(episode_len)
        
        print(f"  âœ… æ‰¾åˆ° {len(episode_data)} episodes")
        print(f"  ğŸ“Š é•¿åº¦ç»Ÿè®¡: min={min(episode_lens)}, max={max(episode_lens)}, mean={np.mean(episode_lens):.1f}")
        
        return episode_data, episode_lens
    
    def _cache_episode(self, ep_info, save_images=True, decode_images=False, compress_images=False):
        """
        ç¼“å­˜å•ä¸ªepisode
        
        Args:
            ep_info: Episodeä¿¡æ¯å­—å…¸
            save_images: æ˜¯å¦ä¿å­˜å›¾åƒæ•°æ®
            decode_images: æ˜¯å¦é¢„è§£ç å›¾åƒä¸ºnumpyæ•°ç»„
            compress_images: æ˜¯å¦å‹ç¼©å›¾åƒæ•°æ®
        """
        episode_idx = ep_info['episode_idx']
        start_idx = ep_info['start_idx']
        end_idx = ep_info['end_idx']
        frame_num = ep_info['length']
        
        # Extract state and action
        states = []
        actions = []
        
        for i in range(start_idx, end_idx):
            frame = self._get_frame(i)
            
            # State: right_arm(6) + right_hand(12) + left_arm(6) + left_hand(12) = 36
            state = np.concatenate([
                frame['observation.state.right_arm_joint_pos'].numpy(),
                frame['observation.state.right_hand_obs'].numpy(),
                frame['observation.state.left_arm_joint_pos'].numpy(),
                frame['observation.state.left_hand_obs'].numpy(),
            ])
            states.append(state)
            
            # Action: 36 dimensions
            action = frame['action'].numpy()
            actions.append(action)
        
        state_array = np.stack(states, axis=0).astype(np.float32)
        action_array = np.stack(actions, axis=0).astype(np.float32)
        
        # Prepare cache data
        cache_data = {
            'episode_idx': episode_idx,
            'state': state_array,
            'action': action_array,
            'frame_num': frame_num,
        }
        
        # Handle images
        if save_images:
            if decode_images:
                # é¢„è§£ç å›¾åƒä¸ºnumpyæ•°ç»„
                cache_data['images_info'] = self._extract_and_decode_images(
                    ep_info, 
                    compress=compress_images
                )
            else:
                # åªä¿å­˜å›¾åƒè·¯å¾„ä¿¡æ¯ï¼ˆåŸæœ‰æ–¹å¼ï¼‰
                cache_data['images_info'] = self._extract_images_info(ep_info)
        else:
            # Just save metadata
            cache_data['images_info'] = {
                'note': 'Images are stored in video files, decode on-demand'
            }
        
        # Save cache
        cache_file = self.cache_dir / f"episode_{episode_idx:06d}.pt"
        torch.save(cache_data, cache_file)
        return cache_file
    
    def _extract_and_decode_images(self, ep_info, compress=False):
        """
        æå–å¹¶é¢„è§£ç å›¾åƒä¸ºnumpyæ•°ç»„
        
        Args:
            ep_info: Episodeä¿¡æ¯
            compress: æ˜¯å¦å‹ç¼©å­˜å‚¨ï¼ˆä½¿ç”¨uint8è€Œä¸æ˜¯float32ï¼‰
        
        Returns:
            dict: åŒ…å«é¢„è§£ç å›¾åƒæ•°ç»„çš„å­—å…¸
        """
        episode_idx = ep_info['episode_idx']
        frame_num = ep_info['length']
        
        # æŸ¥æ‰¾å¯¹åº”çš„bson episodeå›¾ç‰‡
        bson_base = Path("data/baai/data")
        
        images_info = {}
        camera_keys = ['camera_head', 'camera_left_wrist', 'camera_right_wrist']
        
        # éå†actionæ–‡ä»¶å¤¹æŸ¥æ‰¾å¯¹åº”çš„episode
        for action_dir in bson_base.glob("action*"):
            for ep_dir in action_dir.glob(f"episode_{episode_idx}"):
                # æ‰¾åˆ°äº†å¯¹åº”çš„episode
                for cam_key in camera_keys:
                    cam_path = ep_dir / cam_key
                    if cam_path.exists():
                        jpg_files = sorted(cam_path.glob("*.jpg"))[:frame_num]
                        
                        if jpg_files:
                            # é¢„åŠ è½½å¹¶è§£ç æ‰€æœ‰å›¾åƒ
                            images = []
                            for jpg_file in jpg_files:
                                try:
                                    with Image.open(jpg_file) as img:
                                        img_array = np.array(img)
                                        # ç¡®ä¿æ˜¯RGBæ ¼å¼
                                        if img_array.ndim == 2:
                                            img_array = np.stack([img_array] * 3, axis=-1)
                                        images.append(img_array)
                                except Exception as e:
                                    print(f"Warning: Failed to load {jpg_file}: {e}")
                                    # ä½¿ç”¨é›¶å›¾åƒä½œä¸ºå ä½ç¬¦
                                    if images:
                                        images.append(np.zeros_like(images[0]))
                                    else:
                                        images.append(np.zeros((480, 640, 3), dtype=np.uint8))
                            
                            if images:
                                # å †å ä¸º (T, H, W, 3) æ•°ç»„
                                img_array = np.stack(images, axis=0)
                                
                                # å­˜å‚¨ä¸ºuint8èŠ‚çœç©ºé—´
                                if compress or img_array.dtype != np.uint8:
                                    img_array = img_array.astype(np.uint8)
                                
                                images_info[cam_key] = img_array
        
        if not images_info:
            print(f"Warning: No images found for episode {episode_idx}")
            # è¿”å›ç©ºæ•°ç»„
            for cam_key in camera_keys:
                images_info[cam_key] = np.zeros((frame_num, 480, 640, 3), dtype=np.uint8)
        
        # æ·»åŠ å…ƒæ•°æ®æ ‡è®°
        images_info['_decoded'] = True
        images_info['_compressed'] = compress
        
        return images_info
    
    def _extract_images_info(self, ep_info):
        """
        æå–å›¾åƒä¿¡æ¯ï¼ˆä»…è·¯å¾„ï¼Œä¸é¢„è§£ç ï¼‰
        
        ç”±äºLeRobotå°†å›¾åƒå­˜å‚¨åœ¨è§†é¢‘ä¸­ï¼Œè¿™é‡Œæˆ‘ä»¬ä¿å­˜å›¾åƒè·¯å¾„ä¿¡æ¯
        å®é™…å›¾åƒéœ€è¦è§†é¢‘è§£ç åº“æ¥æå–
        """
        # å¦‚æœåŸå§‹bsonæ•°æ®çš„å›¾ç‰‡è¿˜åœ¨ï¼Œå¯ä»¥ä½¿ç”¨é‚£äº›
        # å¦åˆ™éœ€è¦ä»è§†é¢‘è§£ç 
        
        # æŸ¥æ‰¾å¯¹åº”çš„bson episodeå›¾ç‰‡
        bson_base = Path("data/baai/data")
        
        images_info = {}
        camera_keys = ['camera_head', 'camera_left_wrist', 'camera_right_wrist']
        
        # å°è¯•ä»åŸå§‹æ•°æ®æ–‡ä»¶å¤¹æ‰¾å›¾ç‰‡
        episode_idx = ep_info['episode_idx']
        
        # éå†actionæ–‡ä»¶å¤¹æŸ¥æ‰¾å¯¹åº”çš„episode
        for action_dir in bson_base.glob("action*"):
            for ep_dir in action_dir.glob(f"episode_{episode_idx}"):
                # æ‰¾åˆ°äº†å¯¹åº”çš„episode
                for cam_key in camera_keys:
                    cam_path = ep_dir / cam_key
                    if cam_path.exists():
                        jpg_files = sorted([f.name for f in cam_path.glob("*.jpg")])
                        if jpg_files:
                            images_info[cam_key] = {
                                'type': 'file_sequence',
                                'path': str(cam_path),
                                'files': jpg_files[:ep_info['length']]
                            }
        
        if not images_info:
            # å¦‚æœæ‰¾ä¸åˆ°åŸå§‹å›¾ç‰‡ï¼Œè®°å½•è§†é¢‘è·¯å¾„
            images_info['note'] = f"Images stored in videos/, episode {episode_idx}"
            images_info['video_base'] = str(self.dataset_path / "videos")
        
        return images_info


def main():
    parser = argparse.ArgumentParser(description="é¢„å¤„ç†LeRobotæ•°æ®é›†ç”Ÿæˆç¼“å­˜")
    parser.add_argument(
        '--dataset_path',
        type=str,
        default='data/baai/data/lerobot_baai',
        help='LeRobotæ•°æ®é›†è·¯å¾„'
    )
    parser.add_argument(
        '--save_images',
        action='store_true',
        default=True,
        help='æ˜¯å¦ä¿å­˜å›¾åƒæ•°æ®'
    )
    parser.add_argument(
        '--decode_images',
        action='store_true',
        default=False,
        help='é¢„è§£ç å›¾åƒä¸ºnumpyæ•°ç»„ï¼ˆå¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦ï¼Œä½†å ç”¨æ›´å¤šç£ç›˜ç©ºé—´çº¦10GBï¼‰'
    )
    parser.add_argument(
        '--compress_images',
        action='store_true',
        default=False,
        help='å‹ç¼©å›¾åƒå­˜å‚¨ï¼ˆéœ€è¦--decode_imagesï¼Œå¯èŠ‚çœçº¦50%%ç£ç›˜ç©ºé—´ï¼‰'
    )
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print("ğŸš€ LeRobotæ•°æ®é›†ç¼“å­˜ç”Ÿæˆå™¨")
    print("="*70 + "\n")
    
    if args.decode_images:
        print("âš¡ æ€§èƒ½ä¼˜åŒ–æ¨¡å¼ï¼šé¢„è§£ç å›¾åƒ")
        print("ğŸ“ˆ é¢„æœŸè®­ç»ƒé€Ÿåº¦æå‡ï¼š3-4å€ (16 it/s â†’ 60-80 it/s)")
        print("ğŸ’¾ ç£ç›˜ç©ºé—´éœ€æ±‚ï¼šçº¦10GB (å‹ç¼©åçº¦5GB)")
        print()
    
    generator = LerobotCacheGenerator(args.dataset_path)
    generator.generate_cache(
        save_images=args.save_images,
        decode_images=args.decode_images,
        compress_images=args.compress_images
    )
    
    print("\nâœ… å®Œæˆï¼ç°åœ¨å¯ä»¥åœ¨rdtç¯å¢ƒä¸­ä½¿ç”¨ lerobot_Dex_dataset.py äº†")
    
    if args.decode_images:
        print("\nğŸ’¡ ä½¿ç”¨æç¤ºï¼š")
        print("  æ•°æ®åŠ è½½å™¨ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨é¢„è§£ç çš„å›¾åƒ")
        print("  æ— éœ€ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼Œé€Ÿåº¦ä¼šè‡ªåŠ¨æå‡ï¼")


if __name__ == "__main__":
    main()

