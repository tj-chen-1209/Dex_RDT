import os
import json
import yaml
import numpy as np
import torch
from PIL import Image
from pathlib import Path
import sys
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.dirname(current_dir))
from configs.state_vec import STATE_VEC_IDX_MAPPING

class LerobotDexDataset:
    """
    This class is used to sample episodes from the lerobot dataset.
    ç”±äºlerobotæ ¼å¼å°†å›¾ç‰‡å­˜å‚¨åœ¨è§†é¢‘ä¸­,éœ€è¦é¢å¤–çš„åº“æ¥è§£ç ã€‚
    
    æœ¬åŠ è½½å™¨ä½¿ç”¨é¢„å¤„ç†çš„ç¼“å­˜æ–‡ä»¶(.ptæ ¼å¼)æ¥é¿å…ä¾èµ–é¢å¤–çš„åº“ã€‚
    å¦‚éœ€ç”Ÿæˆç¼“å­˜,è¯·åœ¨æœ‰lerobotåº“çš„ç¯å¢ƒä¸­è¿è¡Œ: preprocess_lerobot_cache.py
    """

    def __init__(self, dataset_path="data/baai/data/lerobot_baai", use_cache=True) -> None:
        """
        Initialize the lerobot dataset loader.
        
        Args:
            dataset_path: Path to the lerobot dataset directory
            use_cache: Whether to use cached .pt files (recommended)
        """
        # print("="*70)
        # print("ğŸš€ åˆå§‹åŒ– LerobotDexDataset")
        # print("="*70)
        
        self.DATASET_PATH = dataset_path
        self.DATASET_NAME = "baai"  # ä½¿ç”¨ä¸BsonDexDatasetç›¸åŒçš„åç§°ï¼Œå› ä¸ºæ˜¯åŒä¸€æ•°æ®é›†
        self.use_cache = use_cache
        
        # print(f"ğŸ“‚ æ•°æ®é›†è·¯å¾„: {self.DATASET_PATH}")
        # print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜æ¨¡å¼: {use_cache}")
        
        # Load dataset info
        info_path = Path(dataset_path) / "meta" / "info.json"
        with open(info_path, 'r') as f:
            self.info = json.load(f)
        
        # print(f"ğŸ“Š æ€»Episodes: {self.info['total_episodes']}")
        # print(f"ğŸ“Š æ€»Frames: {self.info['total_frames']}")
        # print(f"ğŸ“Š FPS: {self.info['fps']}")
        
        # Load the config
        with open('configs/base.yaml', 'r') as file:
            config = yaml.safe_load(file)
        self.CHUNK_SIZE = config['common']['action_chunk_size']
        self.IMG_HISORY_SIZE = config['common']['img_history_size']
        self.STATE_DIM = config['common']['state_dim']
        
        # print(f"âš™ï¸  é…ç½®: CHUNK_SIZE={self.CHUNK_SIZE}, IMG_HISTORY_SIZE={self.IMG_HISORY_SIZE}, STATE_DIM={self.STATE_DIM}")
        
        # Load instruction embeddings
        instruction_path = Path(dataset_path) / "instruction.pt"
        if instruction_path.exists():
            # print(f"ğŸ“ æ­£åœ¨åŠ è½½instruction embeddings...")
            self.instruction_embeddings = torch.load(instruction_path)
            # print(f"   âœ… shape={self.instruction_embeddings.shape}")
        else:
            self.instruction_embeddings = None
            # print(f"âš ï¸  æœªæ‰¾åˆ°instruction.ptæ–‡ä»¶")
        
        if use_cache:
            # Load from cache
            # print("ğŸ“¦ æ­£åœ¨åŠ è½½ç¼“å­˜æ•°æ®...")
            self._load_from_cache()
        else:
            raise NotImplementedError(
                "ä¸ä½¿ç”¨ç¼“å­˜æ¨¡å¼éœ€è¦å®‰è£…lerobotåº“ã€‚\n"
                "è¯·è¿è¡Œ preprocess_lerobot_cache.py æ¥ç”Ÿæˆç¼“å­˜æ–‡ä»¶ï¼Œ\n"
                "æˆ–åœ¨æœ‰lerobotçš„ç¯å¢ƒä¸­åˆå§‹åŒ–æ•°æ®é›†ã€‚"
            )
        
        # print(f"âœ… æ•°æ®é›†åˆå§‹åŒ–å®Œæˆï¼å…± {len(self.episode_data)} ä¸ªepisodes")
        # print("="*70)

    def _load_from_cache(self):
        """Load preprocessed cache files."""
        cache_dir = Path(self.DATASET_PATH) / "cache"
        
        if not cache_dir.exists():
            raise FileNotFoundError(
                f"ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}\n"
                f"è¯·å…ˆè¿è¡Œ preprocess_lerobot_cache.py ç”Ÿæˆç¼“å­˜æ–‡ä»¶"
            )
        
        # Load episode metadata
        episode_meta_path = cache_dir / "episode_metadata.pt"
        if not episode_meta_path.exists():
            raise FileNotFoundError(
                f"æœªæ‰¾åˆ°episodeå…ƒæ•°æ®: {episode_meta_path}\n"
                f"è¯·è¿è¡Œ preprocess_lerobot_cache.py ç”Ÿæˆç¼“å­˜"
            )
        
        # print(f"  è¯»å–: {episode_meta_path.relative_to(self.DATASET_PATH)}")
        
        # ä¿®å¤numpyæ¨¡å—è·¯å¾„å…¼å®¹æ€§
        import sys
        sys.modules['numpy._core'] = np.core
        sys.modules['numpy._core.multiarray'] = np.core.multiarray
        sys.modules['numpy._core.numeric'] = np.core.numeric if hasattr(np.core, 'numeric') else np.core
        
        cache_data = torch.load(episode_meta_path, map_location='cpu')
        self.episode_data = cache_data['episode_data']
        episode_lens = cache_data['episode_lens']
        
        # print(f"  âœ… åŠ è½½äº† {len(self.episode_data)} ä¸ªepisodeçš„å…ƒæ•°æ®")
        # print(f"  ğŸ“Š Episodeé•¿åº¦: min={min(episode_lens)}, max={max(episode_lens)}, mean={np.mean(episode_lens):.1f}")
        
        # Calculate sampling weights
        self.episode_sample_weights = np.array(episode_lens) / np.sum(episode_lens)
        
        # Check if cached episode data exists
        self.cache_dir = cache_dir
        sample_ep_file = cache_dir / f"episode_{self.episode_data[0]['episode_idx']:06d}.pt"
        if sample_ep_file.exists():
            # print(f"  âœ… Episodeç¼“å­˜æ–‡ä»¶å·²å‡†å¤‡å°±ç»ª")
            pass
        else:
            pass  # print(f"  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°episodeç¼“å­˜æ–‡ä»¶ {sample_ep_file}")

    def _load_episode_cache(self, episode_idx):
        """
        Load cached episode data.
        
        Args:
            episode_idx: Episode index
            
        Returns:
            dict: Cached episode data containing state, action, images_info
        """
        cache_file = self.cache_dir / f"episode_{episode_idx:06d}.pt"
        
        if not cache_file.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°episodeç¼“å­˜: {cache_file}")
        
        # print(f"  ğŸ“¦ åŠ è½½ç¼“å­˜: episode_{episode_idx:06d}.pt")
        
        # å…¼å®¹ä¸åŒnumpyç‰ˆæœ¬çš„åŠ è½½
        import sys
        import pickle
        
        # ä¿®å¤numpyæ¨¡å—è·¯å¾„å…¼å®¹æ€§
        sys.modules['numpy._core'] = np.core
        sys.modules['numpy._core.multiarray'] = np.core.multiarray
        sys.modules['numpy._core.numeric'] = np.core.numeric if hasattr(np.core, 'numeric') else np.core
        
        try:
            episode_cache = torch.load(cache_file, map_location='cpu')
        except Exception as e:
            # print(f"    âš ï¸  æ ‡å‡†åŠ è½½å¤±è´¥ï¼Œå°è¯•å…¼å®¹æ€§åŠ è½½...")
            # å°è¯•ä½¿ç”¨weights_only=False
            episode_cache = torch.load(cache_file, map_location='cpu', weights_only=False)
        
        # print(f"    State shape: {episode_cache['state'].shape}")
        # print(f"    Action shape: {episode_cache['action'].shape}")
        # print(f"    å¸§æ•°: {episode_cache['frame_num']}")
        
        return episode_cache

    def __len__(self):
        return len(self.episode_data)

    def get_dataset_name(self):
        return self.DATASET_NAME
    
    def _load_image_from_cache(self, images_info, camera_key, frame_idx):
        """
        Load image from cached numpy arrays.
        
        Args:
            images_info: Images info dict from cached episode
            camera_key: Camera key like 'camera_head'
            frame_idx: Frame index
            
        Returns:
            np.ndarray: Image array (H, W, 3)
        """
        try:
            if camera_key not in images_info:
                # print(f"      âš ï¸  æœªæ‰¾åˆ°ç›¸æœº: {camera_key}")
                return np.zeros((480, 640, 3), dtype=np.uint8)
            
            cam_data = images_info[camera_key]
            
            if isinstance(cam_data, np.ndarray):
                # All frames stored as array
                if frame_idx < len(cam_data):
                    return cam_data[frame_idx].astype(np.uint8)
            elif isinstance(cam_data, dict) and 'type' in cam_data:
                # File-based storage (lazy loading)
                if cam_data['type'] == 'file_sequence':
                    img_dir = cam_data['path']
                    img_file = cam_data['files'][frame_idx]
                    img_path = os.path.join(img_dir, img_file)
                    
                    with Image.open(img_path) as img:
                        img_array = np.array(img)
                    if img_array.ndim == 2:
                        img_array = np.stack([img_array] * 3, axis=-1)
                    return img_array.astype(np.uint8)
            
            # print(f"      âš ï¸  æ— æ³•åŠ è½½å›¾åƒ")
            return np.zeros((480, 640, 3), dtype=np.uint8)
            
        except Exception as e:
            # print(f"      âš ï¸  åŠ è½½å›¾åƒå¤±è´¥ {camera_key} frame {frame_idx}: {e}")
            return np.zeros((480, 640, 3), dtype=np.uint8)

    def get_item(self, index: int = None, state_only=False):
        """Get a training sample at a random timestep.

        Args:
            index (int, optional): the index of the episode.
                If not provided, a random episode will be selected.
            state_only (bool, optional): Whether to return only the state.
                In this way, the sample will contain a complete trajectory rather
                than a single timestep. Defaults to False.

        Returns:
            sample (dict): a dictionary containing the training sample.
        """
        # print("\n" + "="*70)
        # print("ğŸ² é‡‡æ ·è®­ç»ƒæ•°æ®")
        # print("="*70)
        
        while True:
            if index is None:
                episode_idx = np.random.choice(
                    len(self.episode_data), p=self.episode_sample_weights)
                episode_info = self.episode_data[episode_idx]
                # print(f"ğŸ¯ éšæœºé€‰æ‹©Episode {episode_info['episode_idx']} (å†…éƒ¨ç´¢å¼•: {episode_idx})")
            else:
                episode_info = self.episode_data[index]
                # print(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šEpisode {episode_info['episode_idx']} (å†…éƒ¨ç´¢å¼•: {index})")
            
            # Parse episode based on state_only flag
            if state_only:
                valid, sample = self.parse_lerobot_episode_state_only(episode_info)
            else:
                valid, sample = self.parse_lerobot_episode(episode_info)
            
            if valid:
                # print("âœ… é‡‡æ ·æˆåŠŸï¼")
                # print("="*70)
                return sample
            else:
                if index is None:
                    # print(f"âš ï¸  Episodeæ— æ•ˆï¼Œé‡æ–°é‡‡æ ·...")
                    continue
                else:
                    raise RuntimeError(f"Episode at index {index} is invalid")

    def parse_lerobot_episode(self, episode_info):
        """
        Parse a lerobot episode to generate a training sample at a random timestep.

        Args:
            episode_info (dict): Episode information dict
            
        Returns:
            valid (bool): whether the episode is valid
            dict: a dictionary containing the training sample
        """
        # Load episode cache
        episode_idx = episode_info['episode_idx']
        episode_cache = self._load_episode_cache(episode_idx)
        
        qpos = episode_cache["state"]
        num_steps = episode_cache["frame_num"]
        
        # print(f"\n  ğŸ” å¤„ç†Episodeæ•°æ®...")
        # print(f"    æ€»æ­¥æ•°: {num_steps}")

        # Skip the first few still steps
        EPS = 1e-2
        qpos_delta = np.abs(qpos - qpos[0:1])
        indices = np.where(np.any(qpos_delta > EPS, axis=1))[0]
        if len(indices) > 0:
            first_idx = indices[0]
        else:
            # print(f"  âŒ æœªæ‰¾åˆ°è¿åŠ¨èµ·å§‹ç‚¹ï¼ˆæ‰€æœ‰qposå˜åŒ–éƒ½å°äº{EPS}ï¼‰")
            return False, None
        
        # print(f"    è¿åŠ¨èµ·å§‹ç´¢å¼•: {first_idx}")

        if first_idx >= num_steps:
            # print(f"  âŒ èµ·å§‹ç´¢å¼•è¶…å‡ºèŒƒå›´")
            return False, None

        # Randomly sample a timestep
        step_id = np.random.randint(first_idx-1, num_steps)
        # print(f"    éšæœºé‡‡æ ·æ­¥æ•°: {step_id}")
        
        # Get instruction
        if self.instruction_embeddings is not None and episode_idx < len(self.instruction_embeddings):
            instruction = self.instruction_embeddings[episode_idx]
            # print(f"    Instruction: embedding shape={instruction.shape}")
        else:
            instruction = "Use the left hand to hook the book 'çš®å›Š' from the pile of books,then use the right hand to place it on the right bookshelf."
            # print(f"    Instruction: ä½¿ç”¨é»˜è®¤æ–‡æœ¬")

        # Assemble the meta
        meta = {
            "dataset_name": self.DATASET_NAME,
            "#steps": num_steps,
            "step_id": step_id,
            "instruction": instruction
        }

        def fill_in_state(values):
            """Fill 36-dim state/action into 128-dim unified vector"""
            UNI_STATE_INDICES = [
                STATE_VEC_IDX_MAPPING[f"right_arm_joint_{i}_pos"] for i in range(6)
            ] + [
                STATE_VEC_IDX_MAPPING[f"right_hand_joint_{i}_pos"] for i in range(12)
            ] + [
                STATE_VEC_IDX_MAPPING[f"left_arm_joint_{i}_pos"] for i in range(6)
            ] + [
                STATE_VEC_IDX_MAPPING[f"left_hand_joint_{i}_pos"] for i in range(12)
            ]
            uni_vec = np.zeros(values.shape[:-1] + (self.STATE_DIM,))
            uni_vec[..., UNI_STATE_INDICES] = values
            return uni_vec

        target_qpos = episode_cache["action"][step_id:step_id+self.CHUNK_SIZE]
        state = qpos[step_id:step_id+1]
        state_std = np.std(qpos, axis=0)
        state_indicator = np.ones_like(state_std)
        state_mean = np.mean(qpos, axis=0)
        state_norm = np.sqrt(np.mean(qpos**2, axis=0))
        actions = target_qpos
        
        # print(f"    åŸå§‹state shape: {state.shape}")
        # print(f"    åŸå§‹action shape: {actions.shape}")
        
        if actions.shape[0] < self.CHUNK_SIZE:
            # Pad the actions using the last action
            actions = np.concatenate([
                actions,
                np.tile(actions[-1:],
                        (self.CHUNK_SIZE-actions.shape[0], 1))
            ], axis=0)
            # print(f"    Actionå·²è¡¥é½åˆ° {actions.shape}")

        # Fill the state into the unified vector
        state = fill_in_state(state)
        state_std = fill_in_state(state_std)
        state_mean = fill_in_state(state_mean)
        state_norm = fill_in_state(state_norm)
        actions = fill_in_state(actions)
        state_indicator = fill_in_state(state_indicator)
        
        # print(f"    å¡«å……åstate shape: {state.shape}")
        # print(f"    å¡«å……åaction shape: {actions.shape}")

        # Parse images on demand - load only the needed frames
        # print(f"\n  ğŸ“· åŠ è½½å›¾åƒ...")
        images_info = episode_cache.get("images_info", {})
        
        def parse_img(cam_key):
            """Load image sequence for a specific camera"""
            # print(f"    åŠ è½½ {cam_key}...")
            
            # Load IMG_HISTORY_SIZE frames around step_id
            start_idx = max(step_id - self.IMG_HISORY_SIZE + 1, 0)
            imgs = []
            
            for i in range(start_idx, step_id + 1):
                img = self._load_image_from_cache(images_info, cam_key, i)
                imgs.append(img)
            
            if len(imgs) == 0:
                # print(f"      âš ï¸  æœªèƒ½åŠ è½½ä»»ä½•å›¾åƒ")
                return np.zeros((self.IMG_HISORY_SIZE, 480, 640, 3), dtype=np.uint8)
            
            imgs = np.stack(imgs)
            
            # Pad images if history is not full
            if imgs.shape[0] < self.IMG_HISORY_SIZE:
                pad_width = self.IMG_HISORY_SIZE - imgs.shape[0]
                imgs = np.pad(imgs, ((pad_width, 0), (0,0), (0,0), (0,0)), 'edge')
            
            # print(f"      âœ… shape: {imgs.shape}")
            return imgs
        
        # Load images from 3 cameras (ä¸ä½¿ç”¨ç¬¬ä¸‰äººç§°æ‘„åƒå¤´)
        cam_high = parse_img('camera_head')
        cam_left_wrist = parse_img('camera_left_wrist')
        cam_right_wrist = parse_img('camera_right_wrist')

        # Create masks
        valid_len = min(step_id - (first_idx - 1) + 1, self.IMG_HISORY_SIZE)
        cam_mask = np.array(
            [False] * (self.IMG_HISORY_SIZE - valid_len) + [True] * valid_len
        )
        
        # print(f"    å›¾åƒmask: valid_len={valid_len}, mask={cam_mask}")

        # print(f"\n  ğŸ“Š æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
        # print(f"    meta: {meta}")
        # print(f"    state: {state.shape}")
        # print(f"    state_std: {state_std.shape}")
        # print(f"    state_mean: {state_mean.shape}")
        # print(f"    state_norm: {state_norm.shape}")
        # print(f"    actions: {actions.shape}")
        # print(f"    state_indicator: {state_indicator.shape}")
        # print(f"    cam_high: {cam_high.shape}")
        # print(f"    cam_high_mask: {cam_mask.shape}")
        # print(f"    cam_left_wrist: {cam_left_wrist.shape}")
        # print(f"    cam_left_wrist_mask: {cam_mask.shape}")
        # print(f"    cam_right_wrist: {cam_right_wrist.shape}")
        # print(f"    cam_right_wrist_mask: {cam_mask.shape}")

        return True, {
            "meta": meta,
            "state": state,
            "state_std": state_std,
            "state_mean": state_mean,
            "state_norm": state_norm,
            "actions": actions,
            "state_indicator": state_indicator,
            "cam_high": cam_high,
            "cam_high_mask": cam_mask,
            "cam_left_wrist": cam_left_wrist,
            "cam_left_wrist_mask": cam_mask.copy(),
            "cam_right_wrist": cam_right_wrist,
            "cam_right_wrist_mask": cam_mask.copy(),
        }

    def parse_lerobot_episode_state_only(self, episode_info):
        """
        Parse a lerobot episode to generate full state and action trajectories.
        ç”¨äºç»Ÿè®¡è®¡ç®—ï¼Œè¿”å›å®Œæ•´è½¨è¿¹è€Œä¸æ˜¯å•ä¸ªæ—¶é—´æ­¥ã€‚
        
        Args:
            episode_info (dict): Episode information dict
            
        Returns:
            valid (bool): whether the episode is valid
            dict: a dictionary containing the full trajectory:
                {
                    "state": ndarray,   # state[:], (T, state_dim)
                    "action": ndarray,  # action[:], (T, action_dim)
                }
        """
        # print(f"\n  ğŸ” æå–å®Œæ•´è½¨è¿¹ï¼ˆstate_onlyæ¨¡å¼ï¼‰...")
        
        # Load episode cache
        episode_idx = episode_info['episode_idx']
        episode_cache = self._load_episode_cache(episode_idx)
        
        qpos = episode_cache["state"]
        actions = episode_cache["action"]
        num_steps = episode_cache["frame_num"]
        
        # print(f"    æ€»æ­¥æ•°: {num_steps}")

        if num_steps < self.CHUNK_SIZE:
            # print(f"  âŒ Episodeå¤ªçŸ­ ({num_steps} < {self.CHUNK_SIZE})")
            return False, None

        # Skip the first few still steps
        EPS = 1e-2
        qpos_delta = np.abs(qpos - qpos[0:1])
        indices = np.where(np.any(qpos_delta > EPS, axis=1))[0]
        first_idx = indices[0] if len(indices) > 0 else 1
        
        # print(f"    è¿åŠ¨èµ·å§‹ç´¢å¼•: {first_idx}")
        
        if first_idx >= num_steps:
            # print(f"  âŒ èµ·å§‹ç´¢å¼•è¶…å‡ºèŒƒå›´")
            return False, None

        # Return full trajectory from first moving frame
        state_traj = qpos[first_idx-1:]
        action_traj = actions[first_idx-1:]
        
        # print(f"    è½¨è¿¹é•¿åº¦: {len(state_traj)}")

        def fill_in_state(values):
            """Fill 36-dim state/action into 128-dim unified vector"""
            UNI_STATE_INDICES = [
                STATE_VEC_IDX_MAPPING[f"right_arm_joint_{i}_pos"] for i in range(6)
            ] + [
                STATE_VEC_IDX_MAPPING[f"right_hand_joint_{i}_pos"] for i in range(12)
            ] + [
                STATE_VEC_IDX_MAPPING[f"left_arm_joint_{i}_pos"] for i in range(6)
            ] + [
                STATE_VEC_IDX_MAPPING[f"left_hand_joint_{i}_pos"] for i in range(12)
            ]
            uni_vec = np.zeros(values.shape[:-1] + (self.STATE_DIM,))
            uni_vec[..., UNI_STATE_INDICES] = values
            return uni_vec

        # å¡«å……stateå’Œactionåˆ°128ç»´
        state_traj = fill_in_state(state_traj)
        action_traj = fill_in_state(action_traj)
        
        # print(f"    å¡«å……åstate shape: {state_traj.shape}")
        # print(f"    å¡«å……åaction shape: {action_traj.shape}")
        # print(f"  âœ… è½¨è¿¹æå–å®Œæˆ")

        return True, {
            "state": state_traj,
            "action": action_traj
        }


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯• LerobotDexDataset")
    print("="*70 + "\n")
    
    ds = LerobotDexDataset()
    
    print(f"\næ•°æ®é›†é•¿åº¦: {len(ds)}")
    
    # Test first episode
    print("\n" + "="*70)
    print("æµ‹è¯•ç¬¬ä¸€ä¸ªEpisode")
    print("="*70)
    sample = ds.get_item(0)
    
    print("\n" + "="*70)
    print("æµ‹è¯•éšæœºEpisode")
    print("="*70)
    sample = ds.get_item()
    
    print("\n" + "="*70)
    print("æµ‹è¯•å®Œæˆï¼")
    print("="*70)
