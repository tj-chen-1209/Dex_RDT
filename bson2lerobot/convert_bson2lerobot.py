#!/usr/bin/env python3
"""BSONåˆ°LeRobotæ ¼å¼è½¬æ¢ - siqi"""
import sys
import yaml
import shutil
import argparse
import os
import bson
import numpy as np
from pathlib import Path
from PIL import Image
import torch
from tqdm import tqdm
from lerobot.datasets.lerobot_dataset import LeRobotDataset


## step1ï¼š ä»bsonå–æ•°æ®
def extract_data_from_bson(episode_path):
    """ä»BSONæ–‡ä»¶ä¸­æå–æ•°æ®"""
    arm_bson = os.path.join(episode_path, "episode_0.bson")
    xhand_bson = os.path.join(episode_path, "xhand_control_data.bson")
    print("extracting data from bson files...")
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not (os.path.exists(arm_bson) and os.path.exists(xhand_bson)):
        print(f"bson files do not exist: {arm_bson} or {xhand_bson}")
        return None
    print("bson files exist...")    
    # è¯»å–BSONæ–‡ä»¶
    try:
        with open(arm_bson, 'rb') as f:
            arm_data = bson.decode(f.read())["data"]
        with open(xhand_bson, 'rb') as f:
            xhand_data = bson.decode(f.read())
    except Exception as e:
        print(f"è¯»å–BSONå¤±è´¥: {e}")
        return None
    print("bson files read successfully...")
    # è·å–å¸§æ•°
    arm_frame_num = len(arm_data["/observation/left_arm/joint_state"])
    xhand_frame_num = len(xhand_data['frames'])
    frame_num = min(arm_frame_num, xhand_frame_num)
    print(f"frame number: {frame_num}")    
    
    # æ£€æŸ¥åŠ¨ä½œæ•°æ®æ˜¯å¦å¯ç”¨
    arm_dim, hand_dim = 6, 12
    use_arm_actions = True
    try:
        left_test = arm_data["/action/left_arm/joint_state"][0]["data"]["pos"]
        right_test = arm_data["/action/right_arm/joint_state"][0]["data"]["pos"]
        if len(left_test) != arm_dim or len(right_test) != arm_dim:
            use_arm_actions = False
    except (KeyError, IndexError):
        use_arm_actions = False
        print("âš ï¸  åŠ¨ä½œæ•°æ®ä¸å¯ç”¨ï¼Œä½¿ç”¨è§‚æµ‹æ•°æ®ä»£æ›¿")
    print(f"use_arm_actions: {use_arm_actions}")
    
    # åˆ†åˆ«å­˜å‚¨å„ä¸ªçŠ¶æ€
    left_arm_pos = []
    right_arm_pos = []
    left_arm_vel = []
    right_arm_vel = []
    left_arm_eff = []
    right_arm_eff = []
    left_hand_obs = []
    right_hand_obs = []
    actions = []
    
    print("Extracting state and action data...")
    for i in range(frame_num):
        # æå–æœºæ¢°è‡‚çŠ¶æ€ï¼ˆä½ç½®ã€é€Ÿåº¦ã€åŠ›çŸ©ï¼‰
        left_arm_pos.append(arm_data["/observation/left_arm/joint_state"][i]["data"]["pos"])
        right_arm_pos.append(arm_data["/observation/right_arm/joint_state"][i]["data"]["pos"])
        left_arm_vel.append(arm_data["/observation/left_arm/joint_state"][i]["data"]["vel"])
        right_arm_vel.append(arm_data["/observation/right_arm/joint_state"][i]["data"]["vel"])
        left_arm_eff.append(arm_data["/observation/left_arm/joint_state"][i]["data"]["eff"])
        right_arm_eff.append(arm_data["/observation/right_arm/joint_state"][i]["data"]["eff"])
        
        # çµå·§æ‰‹çŠ¶æ€ï¼ˆåº¦è½¬å¼§åº¦ï¼‰
        left_hand_obs.append(np.deg2rad(xhand_data['frames'][i]["observation"]["left_hand"]))
        right_hand_obs.append(np.deg2rad(xhand_data['frames'][i]["observation"]["right_hand"]))
        
        # åŠ¨ä½œ
        if use_arm_actions:
            right_arm = arm_data["/action/right_arm/joint_state"][i]["data"]["pos"]
            left_arm = arm_data["/action/left_arm/joint_state"][i]["data"]["pos"]
        else:
            right_arm = arm_data["/observation/right_arm/joint_state"][i]["data"]["pos"]
            left_arm = arm_data["/observation/left_arm/joint_state"][i]["data"]["pos"]
        
        actions.append(np.concatenate([
            right_arm,
            xhand_data['frames'][i]["action"]["right_hand"],
            left_arm,
            xhand_data['frames'][i]["action"]["left_hand"],
        ]))
    
    print("State and action data extracted...")
    # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    camera_folders = ['camera_head', 'camera_left_wrist', 'camera_right_wrist', 'camera_third_view']
    image_files = {}
    print("Getting image files...")
    for cam in camera_folders:
        cam_path = os.path.join(episode_path, cam)
        if not os.path.exists(cam_path):
            print(f"âš ï¸  ç›¸æœºæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {cam}")
            return None
        jpg_files = sorted([f for f in os.listdir(cam_path) if f.endswith('.jpg')])
        image_files[cam] = jpg_files[:frame_num]
        if len(jpg_files) < frame_num:
            print(f"âš ï¸  {cam} å›¾åƒæ•°é‡ä¸è¶³")
            return None
    
    # è¿”å›åˆ†ç¦»çš„å„ä¸ªå­—æ®µ
    return {
        'left_arm_pos': np.array(left_arm_pos, dtype=np.float32),
        'right_arm_pos': np.array(right_arm_pos, dtype=np.float32),
        'left_arm_vel': np.array(left_arm_vel, dtype=np.float32),
        'right_arm_vel': np.array(right_arm_vel, dtype=np.float32),
        'left_arm_eff': np.array(left_arm_eff, dtype=np.float32),
        'right_arm_eff': np.array(right_arm_eff, dtype=np.float32),
        'left_hand_obs': np.array(left_hand_obs, dtype=np.float32),
        'right_hand_obs': np.array(right_hand_obs, dtype=np.float32),
        'action': np.array(actions, dtype=np.float32),
        'frame_num': frame_num,
        'image_files': image_files,
    }

def convert_bson_to_lerobot(
    bson_dir="/home/zhukefei/chensiqi/Dex_RDT/data/baai/data",
    output_repo_id="baai/xhand_bimanual_action176",
    output_root="/home/zhukefei/chensiqi/Dex_RDT/data/baai/data/lerobot_baai",
    fps=20,
    robot_type="xhand_bimanual",
    use_videos=True,
    max_episodes=None,  # æ–°å¢ï¼šé™åˆ¶è½¬æ¢çš„episodeæ•°é‡ï¼ŒNoneè¡¨ç¤ºè½¬æ¢å…¨éƒ¨
):
    """
    å°†BSONæ ¼å¼æ•°æ®é›†è½¬æ¢ä¸ºLeRobotæ ¼å¼
    
    Args:
        bson_dir: BSONæ•°æ®é›†æ ¹ç›®å½•
        output_repo_id: è¾“å‡ºçš„LeRobotæ•°æ®é›†ID
        output_root: è¾“å‡ºæ ¹è·¯å¾„
        fps: å¸§ç‡ï¼ˆé»˜è®¤20ï¼‰
        robot_type: æœºå™¨äººç±»å‹
        use_videos: æ˜¯å¦ä½¿ç”¨è§†é¢‘æ ¼å¼ï¼ˆæ¨èTrueï¼‰
        max_episodes: æœ€å¤šè½¬æ¢çš„episodeæ•°é‡ï¼ŒNoneè¡¨ç¤ºè½¬æ¢å…¨éƒ¨
    """
    
    # 1. å®šä¹‰featuresï¼ˆæ ¹æ®ä½ çš„æ•°æ®ç»“æ„ï¼‰
    features = {
        # è§‚æµ‹ï¼šåŒè‡‚å…³èŠ‚ + åŒæ‰‹å…³èŠ‚
        "observation.state.left_arm_joint_pos": {
            "dtype": "float32", "shape": (6,),
            "names": [f"joint_{i}" for i in range(6)],
        },
        "observation.state.right_arm_joint_pos": {
            "dtype": "float32", "shape": (6,),
            "names": [f"joint_{i}" for i in range(6)],
        },
        "observation.state.left_arm_joint_vel": {
            "dtype": "float32", "shape": (6,),
            "names": [f"joint_{i}" for i in range(6)],
        },
        "observation.state.right_arm_joint_vel": {
            "dtype": "float32", "shape": (6,),
            "names": [f"joint_{i}" for i in range(6)],
        },
        "observation.state.left_arm_joint_eff": {
            "dtype": "float32", "shape": (6,),
            "names": [f"joint_{i}" for i in range(6)],
        },
        "observation.state.right_arm_joint_eff": {
            "dtype": "float32", "shape": (6,),
            "names": [f"joint_{i}" for i in range(6)],
        },
        "observation.state.left_hand_obs": {
            "dtype": "float32", "shape": (12,),
            "names": [f"joint_{i}" for i in range(12)],
        },
        "observation.state.right_hand_obs": {
            "dtype": "float32", "shape": (12,),
            "names": [f"joint_{i}" for i in range(12)],
        },
        # åŠ¨ä½œï¼šä¸è§‚æµ‹ç»´åº¦ç›¸åŒ
        "action": {
            "dtype": "float32",
            "shape": (36,),
            "names": [
                *[f"right_arm_joint_{i}" for i in range(6)],
                *[f"right_hand_joint_{i}" for i in range(12)],
                *[f"left_arm_joint_{i}" for i in range(6)],
                *[f"left_hand_joint_{i}" for i in range(12)],
            ]
        },
        # ç›¸æœºï¼š3ä¸ªè§†è§’
        "observation.images.camera_head_img": {
            "dtype": "video",
            "shape": (480, 640, 3),
            "names": ["height", "width", "channel"]
        },
        "observation.images.camera_left_wrist_img": {
            "dtype": "video",
            "shape": (480, 640, 3),
            "names": ["height", "width", "channel"]
        },
        "observation.images.camera_right_wrist_img": {
            "dtype": "video",
            "shape": (480, 640, 3),
            "names": ["height", "width", "channel"]
        },
        "observation.images.camera_third_view_img": {
            "dtype": "video",
            "shape": (480, 640, 3),
            "names": ["height", "width", "channel"]
        },
    }
    
    print("ğŸ“¦ åˆ›å»ºLeRobotæ•°æ®é›†...")
    dataset = LeRobotDataset.create(
        repo_id=output_repo_id,
        fps=fps,
        features=features,
        robot_type=robot_type,
        root=output_root,
        use_videos=use_videos,
    )
    
    # 2. éå†æ‰€æœ‰actionç›®å½•
    action_dirs = sorted([d for d in os.listdir(bson_dir) if d.startswith('action')])
    
    # è¯»å–ä»»åŠ¡æŒ‡ä»¤
    task_instructions = {}
    task_description = "Use the left hand to hook the book 'çš®å›Š' from the pile of books,then use the right hand to place it on the right bookshelf."
    for action_dir in action_dirs:
        task_instructions[action_dir] = task_description
        
        print(f"ğŸ“‚ æ‰¾åˆ° {len(action_dirs)} ä¸ªactionç›®å½•")
    
    global_ep_idx = 0
    
    # æ˜¾ç¤ºè½¬æ¢æ¨¡å¼
    if max_episodes is not None:
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šä»…è½¬æ¢å‰ {max_episodes} ä¸ªepisodes")
    else:
        print(f"ğŸ“¦ å®Œæ•´è½¬æ¢æ¨¡å¼ï¼šè½¬æ¢æ‰€æœ‰episodes")
    
    for action_dir in tqdm(action_dirs, desc="å¤„ç†actionç›®å½•"):
        # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°æœ€å¤§episodeæ•°é‡
        if max_episodes is not None and global_ep_idx >= max_episodes:
            print(f"\nâœ… å·²è¾¾åˆ°æœ€å¤§episodeæ•°é‡ ({max_episodes})ï¼Œåœæ­¢è½¬æ¢")
            break
            
        action_path = os.path.join(bson_dir, action_dir)
        task = task_instructions.get(action_dir, f"Task {action_dir}")
        
        # è·å–æ‰€æœ‰episode
        episode_dirs = sorted([
            d for d in os.listdir(action_path) 
            if d.startswith('episode') and os.path.isdir(os.path.join(action_path, d))
        ])
        
        for episode_dir in tqdm(episode_dirs, desc=f"  {action_dir}", leave=False):
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°æœ€å¤§episodeæ•°é‡
            if max_episodes is not None and global_ep_idx >= max_episodes:
                break
            episode_path = os.path.join(action_path, episode_dir)
            
            # 3. è¯»å–BSONæ•°æ®
            try:
                episode_data = extract_data_from_bson(episode_path)
                if episode_data is None:
                    print(f"âš ï¸  è·³è¿‡æ— æ•ˆepisode: {episode_path}")
                    continue
            except Exception as e:
                print(f"âŒ è¯»å–episodeå¤±è´¥ {episode_path}: {e}")
                continue
            
            # 4. é€å¸§æ·»åŠ æ•°æ®ï¼ˆä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µåï¼Œæ·»åŠ æ‰€æœ‰ç›¸æœºï¼‰
            frame_num = episode_data['frame_num']
            for frame_idx in range(frame_num):
                # å‡†å¤‡frameæ•°æ®ï¼ˆä¿®å¤ï¼šåˆ†ç¦»å„ä¸ªçŠ¶æ€å­—æ®µï¼‰
                frame = {
                    "observation.state.left_arm_joint_pos": episode_data['left_arm_pos'][frame_idx],
                    "observation.state.right_arm_joint_pos": episode_data['right_arm_pos'][frame_idx],
                    "observation.state.left_arm_joint_vel": episode_data['left_arm_vel'][frame_idx],
                    "observation.state.right_arm_joint_vel": episode_data['right_arm_vel'][frame_idx],
                    "observation.state.left_arm_joint_eff": episode_data['left_arm_eff'][frame_idx],
                    "observation.state.right_arm_joint_eff": episode_data['right_arm_eff'][frame_idx],
                    "observation.state.left_hand_obs": episode_data['left_hand_obs'][frame_idx],
                    "observation.state.right_hand_obs": episode_data['right_hand_obs'][frame_idx],
                    "action": episode_data['action'][frame_idx],
                    "task": task,
                }
                
                # æ·»åŠ æ‰€æœ‰4ä¸ªç›¸æœºå›¾åƒ
                for cam_key, lerobot_key in [
                    ('camera_head', 'observation.images.camera_head_img'),
                    ('camera_left_wrist', 'observation.images.camera_left_wrist_img'),
                    ('camera_right_wrist', 'observation.images.camera_right_wrist_img'),
                    ('camera_third_view', 'observation.images.camera_third_view_img'),
                ]:
                    img_path = os.path.join(
                        episode_path, cam_key, 
                        episode_data['image_files'][cam_key][frame_idx]
                    )
                    img = Image.open(img_path)
                    img_array = np.array(img, dtype=np.uint8)
                    
                    # å¤„ç†ç°åº¦å›¾
                    if img_array.ndim == 2:
                        img_array = np.stack([img_array] * 3, axis=-1)
                    frame[lerobot_key] = img_array
                
                # æ·»åŠ å¸§
                dataset.add_frame(frame)
            
            # 6. ä¿å­˜episode
            dataset.save_episode()
            global_ep_idx += 1
            
            print(f"âœ… Episode {global_ep_idx-1}: {frame_num} frames")
    
    # 7. å®Œæˆæ•°æ®é›†
    print("\nğŸ‰ å®Œæˆè½¬æ¢ï¼Œä¿å­˜æ•°æ®é›†...")
    dataset.finalize()
    print(f"âœ… æ•°æ®é›†å·²ä¿å­˜åˆ°: {dataset.root}")
    print(f"ğŸ“Š æ€»è®¡: {global_ep_idx} episodes, {dataset.meta.total_frames} frames")
    
    return dataset

def load_config(config_path: str) -> dict:
    """åŠ è½½ YAML é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def convert_with_config(config_path: str, override_output: str = None, override_max_episodes: int = None):
    """
    ä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œè½¬æ¢
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        override_output: è¦†ç›–è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        override_max_episodes: è¦†ç›–æœ€å¤§episodeæ•°ï¼ˆå¯é€‰ï¼‰
    """
    # åŠ è½½é…ç½®
    config = load_config(config_path)
    
    # è¯»å–é…ç½®
    output_root = config['data']['output_root']
    max_episodes = config['conversion']['max_episodes']
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if override_output:
        output_root = override_output
        print(f"ğŸ“‚ ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•: {output_root}")
    
    if override_max_episodes is not None:
        max_episodes = override_max_episodes
        print(f"ğŸ“Š è¦†ç›–æœ€å¤§episodesæ•°: {max_episodes}")
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("\n" + "="*70)
    print("ğŸ“‹ è½¬æ¢é…ç½®")
    print("="*70)
    print(f"è¾“å…¥ç›®å½•:     {config['data']['bson_dir']}")
    print(f"è¾“å‡ºç›®å½•:     {output_root}")
    print(f"Repository ID: {config['data']['output_repo_id']}")
    print(f"FPS:          {config['dataset']['fps']}")
    print(f"Robot Type:   {config['dataset']['robot_type']}")
    print(f"Use Videos:   {config['dataset']['use_videos']}")
    print(f"Max Episodes: {max_episodes if max_episodes else 'å…¨éƒ¨'}")
    print(f"Task:         {config['task']['description'][:60]}...")
    print("="*70 + "\n")
    
    # æ‰§è¡Œè½¬æ¢
    try:
        dataset = convert_bson_to_lerobot(
            bson_dir=config['data']['bson_dir'],
            output_repo_id=config['data']['output_repo_id'],
            output_root=output_root,
            fps=config['dataset']['fps'],
            robot_type=config['dataset']['robot_type'],
            use_videos=config['dataset']['use_videos'],
            max_episodes=max_episodes,
        )
        
        print("\n" + "="*70)
        print("âœ… è½¬æ¢å®Œæˆ!")
        print("="*70)
        print(f"è¾“å‡ºä½ç½®:   {dataset.root}")
        print(f"Episodes:   {dataset.meta.total_episodes}")
        print(f"Frames:     {dataset.meta.total_frames}")
        print(f"Tasks:      {dataset.meta.total_tasks}")
        print("="*70)
        
        return True
        
    except Exception as e:
        print("\n" + "="*70)
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        print("="*70)
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(
        description='BSON åˆ° LeRobot æ ¼å¼è½¬æ¢ï¼ˆä½¿ç”¨ YAML é…ç½®ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤é…ç½®è½¬æ¢
  python convert_bson2lerobot.py
  
  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
  python convert_bson2lerobot.py -c config/my_config.yml
  
  # è¦†ç›–è¾“å‡ºç›®å½•
  python convert_bson2lerobot.py -o /path/to/output
  
  # ä»…è½¬æ¢å‰10ä¸ªepisodesï¼ˆæµ‹è¯•ç”¨ï¼‰
  python convert_bson2lerobot.py -n 10
        """
    )
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        default='config/convert.yml',
        help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/convert.yml)'
    )
    
    parser.add_argument(
        '--output-dir', '-o',
        type=str,
        default=None,
        help='è¾“å‡ºç›®å½•ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--max-episodes', '-n',
        type=int,
        default=None,
        help='æœ€å¤šè½¬æ¢çš„episodeæ•°é‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰'
    )
    
    args = parser.parse_args()
    
    # è§£æé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºè„šæœ¬ç›®å½•ï¼‰
    script_dir = Path(__file__).parent
    config_path = script_dir / args.config
    
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    
    # æ‰§è¡Œè½¬æ¢
    success = convert_with_config(
        config_path=str(config_path),
        override_output=args.output_dir,
        override_max_episodes=args.max_episodes
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()